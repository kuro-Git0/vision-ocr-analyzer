import os
import io
import streamlit as st
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from google.cloud import vision
import re
from collections import defaultdict
import json

# âœ… Google Cloud Vision APIèªè¨¼è¨­å®šï¼ˆsecretsã‹ã‚‰èªè¨¼æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ï¼‰
client = vision.ImageAnnotatorClient.from_service_account_info(st.secrets["google_credentials"])

# âœ… ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆæ©Ÿç¨®åãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä¿å­˜ã™ã‚‹ãƒ­ãƒ¼ã‚«ãƒ«JSONãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
MAPPINGS_FILE = "mappings.json"

# âœ… UIåˆæœŸè¨­å®š
st.set_page_config(layout="wide", page_title="ğŸ° ãƒ‘ãƒã‚¹ãƒ­ã‚°ãƒ©ãƒ•è§£æã‚¢ãƒ—ãƒª")
st.title("ğŸ° è§£æã‚¢ãƒ—ãƒª")

# âœ… å‡ºç‰æšæ•°ã®ã—ãã„å€¤
threshold = st.number_input("å‡ºç‰æšæ•°ã®ã—ãã„å€¤ï¼ˆä»¥ä¸Šï¼‰", value=2000, step=1000, key="threshold_input")

# âœ… ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
uploaded_files = st.file_uploader(
    "ğŸ“· ã‚°ãƒ©ãƒ•ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯ï¼‰",
    type=None,
    accept_multiple_files=True
)

# âœ… OCRã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆæœŸåŒ–
if 'ocr_cache' not in st.session_state:
    st.session_state.ocr_cache = {}
if 'manual_corrections' not in st.session_state:
    st.session_state.manual_corrections = {}

# âœ… åç§°ãƒãƒƒãƒ”ãƒ³ã‚°ä¿å­˜ï¼†ãƒ­ãƒ¼ãƒ‰
def load_mappings():
    if os.path.exists(MAPPINGS_FILE):
        with open(MAPPINGS_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_mappings(mappings):
    with open(MAPPINGS_FILE, "w", encoding="utf-8") as f:
        json.dump(mappings, f, ensure_ascii=False, indent=2)

if 'name_mappings' not in st.session_state:
    st.session_state.name_mappings = load_mappings()

# âœ… ã‚°ãƒ©ãƒ•æ¤œå‡º
def detect_graph_rectangles(img_gray):
    blurred = cv2.GaussianBlur(img_gray, (5, 5), 0)
    edged = cv2.Canny(blurred, 30, 150)
    contours, _ = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    rects = []
    for c in contours:
        x, y, w, h = cv2.boundingRect(c)
        if 200 < w < 800 and 200 < h < 800:
            rects.append((x, y, w, h))
    rects = sorted(rects, key=lambda r: (r[1], r[0]))
    return rects

# âœ… OCR
def run_ocr_once(img_cv):
    pil_image = Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))
    buffered = io.BytesIO()
    pil_image.save(buffered, format="PNG")
    image_content = buffered.getvalue()
    image = vision.Image(content=image_content)
    return client.text_detection(image=image)

# âœ… æ©Ÿç¨®åæŠ½å‡º
def extract_machine_name_by_lines(ocr_results):
    lines = ocr_results.full_text_annotation.text.split("\n")[:15]
    for i, line in enumerate(lines):
        if re.search(r"\d+å°", line):
            if i > 0:
                return lines[i - 1].strip()
    return "ä¸æ˜"

# âœ… èµ¤è‰²æ¤œå‡º
def has_red_area(image_bgr):
    hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)
    lower_red1 = np.array([0, 100, 100])
    upper_red1 = np.array([10, 255, 255])
    lower_red2 = np.array([160, 100, 100])
    upper_red2 = np.array([179, 255, 255])
    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
    red_mask = mask1 + mask2
    red_count = cv2.countNonZero(red_mask)
    return red_count >= 50

# âœ… ç”»åƒã«ãƒ†ã‚­ã‚¹ãƒˆæç”»
def draw_text_on_pil_image(pil_img, machine_name, ocr_text):
    draw = ImageDraw.Draw(pil_img)
    try:
        font_path = os.path.join(os.path.dirname(__file__), "NotoSansJP-Medium.ttf")
        font = ImageFont.truetype(font_path, size=24)
    except IOError:
        font = ImageFont.load_default()
    draw.text((10, 5), f"{machine_name}", fill="white", font=font)
    draw.text((10, 35), f"{ocr_text}", fill="white", font=font)
    return pil_img

# âœ… ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆåç§°å¤‰æ›´ï¼‹â¬‡ï¸ãƒœã‚¿ãƒ³ã‚’å·¦å´ã«ï¼‰
st.sidebar.title("ğŸ›  åç§°å¤‰æ›´è¨­å®š")
for i, mapping in enumerate(st.session_state.name_mappings):
    col1, col2 = st.sidebar.columns([1, 5])

    with col1:
        if i < len(st.session_state.name_mappings) - 1:
            if st.button("â¬‡ï¸", key=f"down_{i}"):
                st.session_state.name_mappings[i + 1], st.session_state.name_mappings[i] = (
                    st.session_state.name_mappings[i],
                    st.session_state.name_mappings[i + 1],
                )
                save_mappings(st.session_state.name_mappings)
                st.rerun()

    with col2:
        updated_name_b = st.text_input(
            f"{mapping['name_a']}", value=mapping["name_b"], key=f"name_b_{i}"
        )
        if updated_name_b != mapping["name_b"]:
            st.session_state.name_mappings[i]["name_b"] = updated_name_b
            save_mappings(st.session_state.name_mappings)

# âœ… ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬ç®¡ç†ï¼‰
graph_data_list = []

if uploaded_files:
    for uploaded_file in uploaded_files:
        filename_lower = uploaded_file.name.lower()
        if not (filename_lower.endswith('.jpg') or filename_lower.endswith('.jpeg') or filename_lower.endswith('.png')):
            st.warning(f"ã‚¹ã‚­ãƒƒãƒ—: {uploaded_file.name} ã¯ã‚µãƒãƒ¼ãƒˆå¤–ã§ã™")
            continue

        try:
            image = Image.open(uploaded_file)
            base_width = 780
            w_percent = (base_width / float(image.size[0]))
            h_size = int((float(image.size[1]) * float(w_percent)))
            image_resized = image.resize((base_width, h_size), Image.LANCZOS)
            img_cv = cv2.cvtColor(np.array(image_resized), cv2.COLOR_RGB2BGR)
            img_gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)

            if uploaded_file.name not in st.session_state.ocr_cache:
                ocr_results = run_ocr_once(img_cv)
                st.session_state.ocr_cache[uploaded_file.name] = ocr_results
            else:
                ocr_results = st.session_state.ocr_cache[uploaded_file.name]

            machine_name = extract_machine_name_by_lines(ocr_results)
            existing_names = [m["name_a"] for m in st.session_state.name_mappings]
            if machine_name not in existing_names:
                st.session_state.name_mappings.append({"name_a": machine_name, "name_b": ""})
                save_mappings(st.session_state.name_mappings)
                st.rerun()

            display_name = next(
                (m["name_b"] for m in st.session_state.name_mappings if m["name_a"] == machine_name and m["name_b"]),
                machine_name
            )

            rects = detect_graph_rectangles(img_gray)

            for idx, (x, y, w, h) in enumerate(rects):
                crop = img_cv[y:y + h, x:x + w]
                crop_rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)
                pil_crop = Image.fromarray(crop_rgb)

                red_detected = has_red_area(crop)
                red_status = "ã€‡èµ¤ã‚ã‚Š" if red_detected else "Ã—èµ¤ãªã—"

                default_key = f"{display_name}_graph_{idx + 1}"
                manual_value = st.session_state.manual_corrections.get(default_key, "")

                graph_data_list.append({
                    "machine": display_name,
                    "index": idx + 1,
                    "image": pil_crop,
                    "red_status": red_status,
                    "manual_key": default_key,
                    "manual_value": manual_value
                })

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")

# âœ… ã‚°ãƒ©ãƒ•ç•ªå·ã§ã‚½ãƒ¼ãƒˆã—ã¦è¡¨ç¤º
if graph_data_list:
    sorted_graphs = sorted(graph_data_list, key=lambda x: (x["machine"], x["index"]))
    cols = st.columns(4)
    for i, data in enumerate(sorted_graphs):
        col = cols[i % 4]
        with col:
            # ç”»åƒå†…ã«ãƒ†ã‚­ã‚¹ãƒˆæç”»
            annotated_img = draw_text_on_pil_image(
                data["image"].copy(),
                f"{data['machine']} ã‚°ãƒ©ãƒ• {data['index']}",
                f"OCRçµæœ: {data['manual_value']} / {data['red_status']}"
            )
            col.image(annotated_img, use_container_width=True)

            # ä¿®æ­£æ¬„
            corrected = st.text_input(
                f"{data['machine']} ã‚°ãƒ©ãƒ• {data['index']} å‡ºç‰ä¿®æ­£",
                value=data["manual_value"],
                key=f"correct_{data['manual_key']}"
            )
            # æ›´æ–°æ™‚ã«ä¿å­˜
            st.session_state.manual_corrections[data["manual_key"]] = corrected

# âœ… å‡ºåŠ›çµæœ
if graph_data_list:
    st.subheader("ğŸ“Š å‡ºåŠ›çµæœ")
    output_texts = []
    machine_group = defaultdict(list)
    for data in graph_data_list:
        val_text = st.session_state.manual_corrections.get(data["manual_key"], "")
        try:
            val = int(val_text)
            machine_group[data["machine"]].append(val)
        except:
            continue

    for mapping in st.session_state.name_mappings:
        machine = mapping["name_b"] if mapping["name_b"] else mapping["name_a"]
        vals = [v for v in machine_group.get(machine, []) if v >= threshold]
        header = f"â–¼{machine} ({len(vals)}/{len(machine_group.get(machine, []))})"
        output_texts.append(header)
        for val in sorted(vals, reverse=True):
            if val >= 19000:
                output_texts.append(f"ãŠ—ï¸{val}æš ã‚³ãƒ³ãƒ—ï¼")
            elif val >= 10000:
                output_texts.append(f"ğŸ‰{val}æš")
            elif val >= 8000:
                output_texts.append(f"ğŸš¨{val}æš")
            elif val >= 5000:
                output_texts.append(f"âœ¨{val}æš")
            else:
                output_texts.append(f"ãƒ»{val}æš")
        output_texts.append("")
    st.code("\n".join(output_texts), language="")